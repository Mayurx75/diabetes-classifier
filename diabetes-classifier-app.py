# -*- coding: utf-8 -*-
"""diabetes-binary-classifiers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19eYyI3wMLxVxr9hjOfpmIwJX_T8Xjab4
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

# Set page configuration
st.set_page_config(
    page_title="Diabetes Prediction App",
    page_icon="ðŸ©º",
    layout="wide"
)

# Page title and description
st.title("Diabetes Prediction using Logistic Regression")
st.markdown("""
This app predicts the likelihood of diabetes based on several health metrics using
a Logistic Regression model trained on the Pima Indians Diabetes Dataset.
""")

# Load data
@st.cache_data
def load_data():
    url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
    column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                   'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
    df = pd.read_csv(url, names=column_names)
    return df

df = load_data()

# Sidebar
st.sidebar.header("User Input Features")
st.sidebar.markdown("Enter your health metrics to predict diabetes risk")

# Sidebar inputs
def user_input_features():
    pregnancies = st.sidebar.slider('Pregnancies', 0, 17, 3)
    glucose = st.sidebar.slider('Glucose (mg/dL)', 0, 200, 117)
    blood_pressure = st.sidebar.slider('Blood Pressure (mm Hg)', 0, 122, 72)
    skin_thickness = st.sidebar.slider('Skin Thickness (mm)', 0, 99, 23)
    insulin = st.sidebar.slider('Insulin (mu U/ml)', 0, 846, 30)
    bmi = st.sidebar.slider('BMI (kg/mÂ²)', 0.0, 67.1, 32.0)
    dpf = st.sidebar.slider('Diabetes Pedigree Function', 0.078, 2.42, 0.3725)
    age = st.sidebar.slider('Age (years)', 21, 81, 29)

    data = {
        'Pregnancies': pregnancies,
        'Glucose': glucose,
        'BloodPressure': blood_pressure,
        'SkinThickness': skin_thickness,
        'Insulin': insulin,
        'BMI': bmi,
        'DiabetesPedigreeFunction': dpf,
        'Age': age
    }
    return pd.DataFrame(data, index=[0])

# Get user input
user_input = user_input_features()

# Preprocess data and train model
def process_and_train():
    # Replace zeros with NaN in specific columns
    df_processed = df.copy()
    for column in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:
        df_processed[column] = df_processed[column].replace(0, np.NaN)

    # Fill NaN values with the mean of the column
    df_processed.fillna(df_processed.mean(), inplace=True)

    # Separate features and target
    X = df_processed.drop('Outcome', axis=1)
    y = df_processed['Outcome']

    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train the model
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train_scaled, y_train)

    # Evaluate model
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:,1]

    return model, scaler, X_train, X_test_scaled, y_train, y_test, y_pred, y_pred_proba, df_processed

# Train model and get results
model, scaler, X_train, X_test, y_train, y_test, y_pred, y_pred_proba, df_processed = process_and_train()

# Make prediction on user input
user_input_scaled = scaler.transform(user_input)
prediction = model.predict(user_input_scaled)
prediction_proba = model.predict_proba(user_input_scaled)

# Display data exploration
st.header("Data Exploration")
tabs = st.tabs(["Data Overview", "Feature Distributions", "Correlation Analysis"])

with tabs[0]:
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Raw Data Sample")
        st.dataframe(df.head())

    with col2:
        st.subheader("Statistical Summary")
        st.dataframe(df.describe())

    st.subheader("Class Distribution")
    fig, ax = plt.subplots(figsize=(8, 4))
    outcome_counts = df['Outcome'].value_counts()
    sns.barplot(x=outcome_counts.index, y=outcome_counts.values, palette=['blue', 'red'])
    plt.title('Distribution of Outcome Classes')
    plt.xlabel('Outcome (0: No Diabetes, 1: Diabetes)')
    plt.ylabel('Count')
    ax.bar_label(ax.containers[0])
    st.pyplot(fig)

with tabs[1]:
    st.subheader("Feature Distributions by Outcome")
    fig = plt.figure(figsize=(16, 12))
    features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

    for i, feature in enumerate(features):
        plt.subplot(3, 3, i+1)
        sns.histplot(data=df_processed, x=feature, hue='Outcome', kde=True,
                    palette=['blue', 'red'], element="step")
        plt.title(f'Distribution of {feature} by Outcome')

    plt.tight_layout()
    st.pyplot(fig)

    st.subheader("Pair Plot of Key Features")
    fig = plt.figure(figsize=(12, 8))
    key_features = ['Glucose', 'BMI', 'Age', 'DiabetesPedigreeFunction', 'Outcome']
    g = sns.pairplot(df_processed[key_features], hue='Outcome', palette=['blue', 'red'], corner=True)
    plt.tight_layout()
    st.pyplot(g.fig)

with tabs[2]:
    st.subheader("Correlation Heatmap")
    fig, ax = plt.subplots(figsize=(12, 10))
    correlation_matrix = df_processed.corr()
    mask = np.triu(correlation_matrix)
    heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm',
                        fmt='.2f', linewidths=.5, mask=mask)
    plt.title('Correlation Heatmap of Features')
    st.pyplot(fig)

# Model insights
st.header("Model Insights and Evaluation")
tabs2 = st.tabs(["Model Performance", "Feature Importance", "ROC Curve"])

with tabs2[0]:
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Confusion Matrix")
        cm = confusion_matrix(y_test, y_pred)
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
        plt.title('Confusion Matrix')
        plt.ylabel('Actual')
        plt.xlabel('Predicted')
        st.pyplot(fig)

    with col2:
        st.subheader("Classification Report")
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df)

        accuracy = accuracy_score(y_test, y_pred)
        st.metric("Model Accuracy", f"{accuracy:.2%}")

with tabs2[1]:
    st.subheader("Feature Importance")
    feature_importance = pd.DataFrame({
        'Feature': df.columns[:-1],
        'Importance': np.abs(model.coef_[0])
    })
    feature_importance = feature_importance.sort_values('Importance', ascending=False)

    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='viridis')
    plt.title('Feature Importance (Absolute Coefficient Values)')
    plt.tight_layout()
    st.pyplot(fig)

with tabs2[2]:
    st.subheader("ROC Curve")
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    fig, ax = plt.subplots(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    st.pyplot(fig)

# Prediction section
st.header("Diabetes Prediction")
st.subheader("User Input Features")
st.dataframe(user_input)

# Display prediction
st.subheader("Prediction Result")
col1, col2 = st.columns(2)

with col1:
    if prediction[0] == 0:
        st.success("**Result: Negative (No Diabetes)**")
    else:
        st.error("**Result: Positive (Diabetes)**")

    st.metric("Probability of Diabetes", f"{prediction_proba[0][1]:.2%}")

with col2:
    # Create gauge chart for probability
    fig, ax = plt.subplots(figsize=(6, 4))

    # Create probability gauge
    prob = prediction_proba[0][1]
    colors = ['green', 'yellow', 'orange', 'red']
    positions = [0, 0.25, 0.5, 0.75, 1]
    cmap = plt.cm.RdYlGn_r
    norm = plt.Normalize(0, 1)

    # Draw the gauge background
    plt.barh(0, 1, color='lightgray', alpha=0.3, height=0.6)

    # Draw the probability value
    plt.barh(0, prob, color=cmap(norm(prob)), height=0.6)

    # Customize the plot
    plt.xlim(0, 1)
    plt.ylim(-0.5, 0.5)
    plt.yticks([])
    plt.xticks(positions, ['0%', '25%', '50%', '75%', '100%'])
    plt.title('Diabetes Risk Level')
    ax.axvline(x=0.25, color='gray', linestyle='--', alpha=0.3)
    ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.3)
    ax.axvline(x=0.75, color='gray', linestyle='--', alpha=0.3)

    # Add a marker for the probability value
    plt.plot(prob, 0, marker='o', markersize=10, color='black')

    # Add risk labels
    if prob < 0.25:
        risk_level = "Low Risk"
    elif prob < 0.5:
        risk_level = "Moderate Risk"
    elif prob < 0.75:
        risk_level = "High Risk"
    else:
        risk_level = "Very High Risk"

    plt.annotate(risk_level, xy=(prob, 0.2), xytext=(prob, 0.2),
                ha='center', fontsize=12, fontweight='bold')

    st.pyplot(fig)

# Information about the model
st.header("About the Model")
st.markdown("""
This model uses Logistic Regression to predict the probability of diabetes based on several health metrics.
The model was trained on the Pima Indians Diabetes Dataset, which contains health data from 768 individuals.

**Key features used for prediction:**
- Pregnancies: Number of times pregnant
- Glucose: Plasma glucose concentration (2 hours in an oral glucose tolerance test)
- Blood Pressure: Diastolic blood pressure (mm Hg)
- Skin Thickness: Triceps skin fold thickness (mm)
- Insulin: 2-Hour serum insulin (mu U/ml)
- BMI: Body mass index (weight in kg/(height in m)Â²)
- Diabetes Pedigree Function: A function that scores likelihood of diabetes based on family history
- Age: Age in years

**Model Performance:**
- The model achieves approximately 78% accuracy on the test set
- Glucose level and BMI are among the most important predictors
""")

# Footer
st.markdown("---")
st.markdown("Developed for educational purposes | 2025")

!pip install streamlit

